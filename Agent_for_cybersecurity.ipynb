{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGqaYtTj8dGQ3L9KqPpXKD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Latakumari-17/Agent_AI_cybersecurity-threat_detection/blob/main/Agent_for_cybersecurity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()\n"
      ],
      "metadata": {
        "id": "KSYPPRf_dsX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "MgiN-YMCd8qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d dnkumars/cybersecurity-intrusion-detection-dataset\n",
        "!unzip cybersecurity-intrusion-detection-dataset.zip -d cybersecurity-intrusion-detection-dataset\n"
      ],
      "metadata": {
        "id": "3oOHibcXeZ5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('cybersecurity-intrusion-detection-dataset/cybersecurity_intrusion_data.csv')\n",
        "print(df.shape)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "H2UGBndVjjkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h62yJAr1bHK_"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(df.info())\n",
        "print(df.describe())\n",
        "print(df.columns)\n",
        "print(\"Missing values per column:\\n\", df.isnull().sum())\n",
        "print(\"Duplicate rows:\", df.duplicated().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df['attack_detected'].value_counts().plot(kind='bar', color=['blue', 'black'])\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.xlabel(\"Class (0 = Normal, 1 = Attack)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vUi4BnWKiyoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "for col in df.select_dtypes(include='object').columns:\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n"
      ],
      "metadata": {
        "id": "y36wc78JoRm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('attack_detected', axis=1)\n",
        "y = df['attack_detected']\n"
      ],
      "metadata": {
        "id": "Ajum1y4Zm2gA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n"
      ],
      "metadata": {
        "id": "lo328V4DoMAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Before SMOTE:\\n\", y_train.value_counts())\n",
        "print(\"After SMOTE:\\n\", y_train_resampled.value_counts())\n"
      ],
      "metadata": {
        "id": "DlH5uzlupX3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
        "model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"\\nClassification Report After SMOTE:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "ConfusionMatrixDisplay(cm).plot()\n"
      ],
      "metadata": {
        "id": "4Nnhk1nXoqoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(model, 'rf_model.pkl')\n",
        "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
        "joblib.dump(X.columns.to_list(), 'feature_columns.pkl')\n"
      ],
      "metadata": {
        "id": "kh0ghtnDpTaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "decoded_preds = label_encoder.inverse_transform(y_pred.astype(int))  # if target was encoded before\n",
        "print(\"Sample predictions:\", decoded_preds[:10])\n"
      ],
      "metadata": {
        "id": "xJB0DCXYptnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scapy\n"
      ],
      "metadata": {
        "id": "6hJPHwkvIhVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scapy.all import sniff, IP, TCP\n",
        "import joblib\n",
        "\n",
        "\n",
        "# Load model and label encoder\n",
        "model = joblib.load('rf_model.pkl')\n",
        "feature_columns = joblib.load('feature_columns.pkl')\n",
        "\n",
        "# Function to extract basic features from a packet\n",
        "def extract_features(packet):\n",
        "    if IP in packet:\n",
        "        ip_layer = packet[IP]\n",
        "        length = len(packet)\n",
        "        proto = packet.proto if hasattr(packet, 'proto') else 0\n",
        "        src_ip = int(ip_layer.src.replace('.', ''))\n",
        "        dst_ip = int(ip_layer.dst.replace('.', ''))\n",
        "        return [src_ip, dst_ip, length, proto]\n",
        "    return None\n",
        "\n",
        "# Process captured packets\n",
        "def process_packet(packet):\n",
        "    features = extract_features(packet)\n",
        "    if features:\n",
        "        # Pad or align to expected features\n",
        "        input_array = np.zeros(len(feature_columns))\n",
        "        input_array[:len(features)] = features\n",
        "        prediction = model.predict([input_array])[0]\n",
        "        if prediction == 1:\n",
        "            print(f\" Alert: Potential attack detected from {packet[IP].src}\")\n",
        "        else:\n",
        "            print(f\"Normal packet from {packet[IP].src}\")\n",
        "\n",
        "# Start sniffing (you can set a count limit for testing)\n",
        "sniff(prn=process_packet, store=False, count=10)\n"
      ],
      "metadata": {
        "id": "5kVth-NcIafD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}